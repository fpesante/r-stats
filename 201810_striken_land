#######################################################################
# Matthew L. Jockers, Text Analysis with R for Students of Literature #
#######################################################################
## 		C.2 First Foray into Text Analysis with R [p.11] 	   ##
#######################################################################


###	2.1 Loading the First Text File	###

setwd("C:~/striken_land")
text.v <- scan("sl-book-txt.txt", what="character", sep="\n")
text.v[2]

###	2.2 Separate Content from Metadata	###

start.v <- which(text.v == "INTRODUCTION")
end.v <- which(text.v == "look to their own benefit.")

length(text.v)

start.metadata.v <- text.v[1:start.v -1]
end.metadata.v <- text.v[(end.v+1):length(text.v)]
metadata.v <- c(start.metadata.v, end.metadata.v)
#diary <- novel
diary.lines.v <- text.v[start.v:end.v]

metadata.v <- c(text.v[1:(start.v-1)], text.v[(end.v+1):length(text.v)])

text.v[start.v]
text.v[start.v-1]
text.v[end.v]
text.v[end.v+1]

length(text.v)
length(diary.lines.v)

diary.v <- paste(diary.lines.v, collapse=" ")

length(diary.v)

diary.v[1]

###	2.3 Reprocessing the Content	###

#striken <- moby
diary.lower.v <- tolower(diary.v)
striken.words.l <- strsplit(diary.lower.v, "\\W")

class(diary.lower.v)
class(striken.words.l)

str(striken.words.l)

striken.word.v <- unlist(striken.words.l)

not.blanks.v <- which(striken.word.v!="")

striken.word.v <- striken.word.v[not.blanks.v]

striken.word.v[1:10]

which(striken.word.v=="agriculture")
#which(striken.word.v=="agricultural")
#which(striken.word.v=="rice")
#which(striken.word.v=="WPA")
#which(striken.word.v=="price index")
#which(striken.word.v=="500 acres")
#which(striken.word.v=="land")

striken.word.v[which(striken.word.v=="agriculture")]


###	2.4 Beginning the Analysis	###

#veces que ocurre
length(striken.word.v[which(striken.word.v=="agriculture")])
length(striken.word.v)

# Put a count of the occurrences of agriculture into agriculture.hits.v
agriculture.hits.v <- length(striken.word.v[which(striken.word.v=="agriculture")])

# Put a count of total words into total.words.v
total.words.v <- length(striken.word.v)

# now divide
agriculture.hits.v/total.words.v

length(unique(striken.word.v))

striken.freqs.t <- table(striken.word.v)
sort(striken.freqs.t)
rev(striken.freqs.t)

sorted.striken.freqs.t <- sort(striken.freqs.t , decreasing=TRUE)

#######################################################################
##	C.3 Accessing and Comparing Word Frequency Data [p. 25]	   ##
#######################################################################

###	3.1 Accessing Word Data	###
sorted.striken.freqs.t["agriculture"]
sorted.striken.freqs.t["agricultural"]
sorted.striken.freqs.t["land"]
sorted.striken.freqs.t["unemployment"]
sorted.striken.freqs.t["hunger"]
sorted.striken.freqs.t["starvation"]

striken.word.v[4:6]
sorted.striken.freqs.t[1]
sorted.striken.freqs.t["the"]

sorted.striken.freqs.t["him"]/sorted.striken.freqs.t["her"]
sorted.striken.freqs.t["he"]/sorted.striken.freqs.t["she"]

length(striken.word.v)

###	3.2 Recycling	###

sorted.striken.rel.freqs.t <- 100*(sorted.striken.freqs.t/sum(sorted.striken.freqs.t))

num.vector.v <- c(1,2,3,4,5)
num.vector.v * 10
sorted.striken.rel.freqs.t["the"]

plot(sorted.striken.rel.freqs.t[1:10], type="b",
xlab="Top Ten Words", ylab="Percentage of Full Text", xaxt ="n")
axis(1,1:10, labels=names(sorted.striken.rel.freqs.t [1:10]))

#######################################################################
##		C. 4 Token Distribution Analysis [p. 29]			   ##
#######################################################################

###	4.1 Dispersion Plots	###

n.time.v <- seq(1:length(striken.word.v))

agriculture.v <- which(striken.word.v == "agriculture")

w.count.v <- rep(NA,length(n.time.v))

w.count.v[agriculture.v] <- 1

plot(w.count.v, main="Dispersion Plot of 'agriculture' in The Striken Land",
xlab="Novel Time", ylab="agriculture", type="h", ylim=c(0,1), yaxt='n')

# sorted.striken.freqs.t["bolivar"]
# n.time.v <- seq(1:length(striken.word.v))
# bolivar.v <- which(striken.word.v == "bolivar")
# w.count.v <- rep(NA,length(n.time.v))
# w.count.v[bolivar.v] <- 1
# plot(w.count.v, main="Dispersion Plot of 'Bolivar' in The Striken Land",
# xlab="Novel Time", ylab="bolivar", type="h", ylim=c(0,1), yaxt='n')

agriculture.v <- which(striken.word.v == "agriculture") # find "agriculture"
a.count.v <- rep(NA,length(n.time.v))
# change 'w' to 'a' to keep bolivar and agriculture in separate variables
a.count.v[agriculture.v] <- 1 # mark the occurrences with a 1
plot(a.count.v, main="Dispersion Plot of 'agriculture' in The Striken Land",
xlab="Novel Time", ylab="agric", type="h", ylim=c(0,1), yaxt='n')


###	4.2 Searching with grep		###
####	4.2.1 Cleaning the Workspace	####

#rm(list = ls())

text.v <- scan("C:/Users/francisco.pesante/Documents/2018/04_personal/agric/striken_land/sl-book-txt.txt", what="character", sep="\n")
start.v <- which(text.v == "CHAPTER 1")
end.v <- which(text.v == "-END-")
#novel -> diary
diary.lines.v <- text.v[start.v:end.v]

#start.v <- which(text.v == "CHAPTER 1")
#end.v <- which(text.v == "CHAPTER 2")
#diary.lines.v <- text.v[start.v:end.v]

#diary.lines.v

####	4.2.2 Identify the chapter break positions in the vector using the grep function	####
#?grep

#*identificar las delimitaciones existentes, a partir de los parametros establecidos. En este caso "CHAPTER"##
#*estas fueron preparadas a manos al convertir el contenido del pdf a txt.##

chap.positions.v <- grep("^CHAPTER \\d", diary.lines.v)
diary.lines.v[chap.positions.v]

#*posicion de las delimitaciones

chap.positions.v

#*marcando el final
diary.lines.v <- c(diary.lines.v, "END")
last.position.v <- length(diary.lines.v)
chap.positions.v <- c(chap.positions.v , last.position.v)
chap.positions.v

###4.3 The for Loop and if Conditional###
#**A for loop allows us to do a task over and over again for a set number of iterations. In this case, the number of iterations will be equal to the number of chapters found in the text.

#**se esta identificando el index number para conocer la posicion de cada capitulo, individual

chap.positions.v[1]
chap.positions.v[2]

#**automatizar lo anterior para todos los capitulos: for loop

for(i in 1:length(chap.positions.v)){
	print(chap.positions.v[i])
}

#**anyadir nombre de capitulo a posicion

for(i in 1:length(chap.positions.v)){
print(paste("Chapter ",i, " begins at position ",
chap.positions.v[i]), sep="")
}

#*no entiendo el uso de lo siguiente
chapter.raws.l <- list()
chapter.freqs.l <- list()

#*what to do when i is equal to the length of chap.positions.v. : if loop

for(i in 1:length(chap.positions.v)){
if(i != length(chap.positions.v)){
chapter.title <- diary.lines.v[chap.positions.v[i]]
start <- chap.positions.v[i]+1
end <- chap.positions.v[i+1]-1
chapter.lines.v <- diary.lines.v[start:end]
chapter.words.v <- tolower(paste(chapter.lines.v, collapse=" "))
chapter.words.l <- strsplit(chapter.words.v, "\\W")
chapter.word.v <- unlist(chapter.words.l)
chapter.word.v <- chapter.word.v[which(chapter.word.v!="")]
chapter.freqs.t <- table(chapter.word.v)
chapter.raws.l[[chapter.title]] <- chapter.freqs.t
chapter.freqs.t.rel <- 100*(chapter.freqs.t/sum(chapter.freqs.t))
chapter.freqs.l[[chapter.title]] <- chapter.freqs.t.rel
}
}


###4.4 Accessing and Processing List Items###

#**If you want to know the relative frequency of the word type whale in the first chapter, you could get the value using bracketed subsetting, like this
chapter.freqs.l[[1]]["agriculture"]
chapter.freqs.l[[2]]["agriculture"]
chapter.freqs.l[[3]]["agriculture"]
chapter.freqs.l[[4]]["agriculture"]
chapter.freqs.l[[5]]["agriculture"]
chapter.freqs.l[[6]]["agriculture"]
chapter.freqs.l[[7]]["agriculture"]
chapter.freqs.l[[8]]["agriculture"]
chapter.freqs.l[[9]]["agriculture"]
chapter.freqs.l[[10]]["agriculture"]

#*para atender el tema de agricultura, parece ser que el capitulo 2 es el de mayor frecuencia en referencias

lapply(chapter.freqs.l, '[', 'agriculture')

agriculture.l <- lapply(chapter.freqs.l, '[', 'agriculture')
#agricultural		agricultural.l <- lapply(chapter.freqs.l, '[', 'agricultural')
#land		land.l <- lapply(chapter.freqs.l, '[', 'land')

rbind(agriculture.l[[1]], agriculture.l[[2]], agriculture.l[[3]])
rbind(agriculture.l,'[')

####4.4.4 do.call (Do Dot Call)####
agriculture.m <- do.call(rbind, agriculture.l)
#agricultural		agricultural.m <- do.call(rbind, agricultural.l)
#land		lapply(chapter.freqs.l, '[', 'land')
#			rbind(land.l,'[')
#			land.m <- do.call(rbind, land.l)

####4.4.5 cbind####
class(agriculture.m[,1])

agriculture.v <- agriculture.m[,1]
land.v <- land.m[,1]
#class(land.m[,1])
agric.land.m <- cbind(agriculture.v, land.v)
dim(agric.land.m )

colnames(agric.land.m) <- c("agriculture", "land")
barplot(agric.land.m, beside=T, col="grey")

#######################################################################
## 		Chapter 5. Correlation					[p. 47] ##
#######################################################################
### 5.2 Correlation Analysis	###

agriculture.l <- lapply(chapter.freqs.l, "[", "agriculture")

agric.land.m[1:16, ]

#** to remove na
agric.land.m[which(is.na(agric.land.m))] <- 0

#** run the correlation
cor(agric.land.m)

mycor <- cor(agric.land.m[,"agriculture"], agric.land.m[,"land"])
mycor

#*Pearson Product-moment correlation coefficient|moderada positiva|https://www.dummies.com/education/math/statistics/how-to-interpret-a-correlation-coefficient-r/


### 5.4  Testing Correlation with Randomization	###

#** convert to a data frame
cor.data.df <- as.data.frame(agric.land.m)
cor(cor.data.df)

#** shuffle for random ordering and eliminating a correlation as a mere chance
sample(cor.data.df$agric)

cor(sample(cor.data.df$agriculture), cor.data.df$land)

#* por los resultados cambiantes conviene generar una muestra grande
mycors.v <- NULL
	for(i in 1:10000){
	mycors.v <- c(mycors.v, cor(sample(cor.data.df$agriculture), cor.data.df$land))
}

#* ver las medidas de dispersion y de tendencia central
min(mycors.v)
max(mycors.v)
range(mycors.v)
mean(mycors.v)
sd(mycors.v)

#** generar histograma
h <- hist(mycors.v, breaks=100, col="grey",
	xlab="Correlation Coefficient",
	main="Histogram of Random Correlation Coefficients\n
	with Normal Curve",
	plot=T)
xfit <- seq(min(mycors.v),max(mycors.v),length=1000)
yfit <- dnorm(xfit,mean=mean(mycors.v),sd=sd(mycors.v))
yfit <- yfit*diff(h$mids[1:2])*length(mycors.v)
lines(xfit, yfit, col="black", lwd=2)

#######################################################################
#	Part II. Mesoanalysis							   #
#######################################################################
#######################################################################
## 	Chapter 6 - Measures of Lexical Variety				  ##
#######################################################################

#** type-token ratio (TTR)

# 6.2 Mean Word Frequency #

#* To calculate mean word frequency on a chapter-by-chapter basis
length(chapter.raws.l)

names(chapter.raws.l)

class(chapter.raws.l$"CHAPTER 1")	#**class(chapter.raws.l[[1]])

chapter.raws.l$"CHAPTER 1"	#**chapter.raws.l[[1]]
#x <-sort(chapter.raws.l$"CHAPTER 1")
#write.csv(x, "striken_land_c1.csv")
#getwd()

#*suma las frecuencias de palabras para el capitulo seleccionado
sum(chapter.raws.l[[1]])

#*cuenta las palabras (token words)
length(chapter.raws.l[[1]])

#**calculate the mean word frequency
sum(chapter.raws.l[[1]])/length(chapter.raws.l[[1]]) 
#**lo anterior pero de forma mas sencilla
mean(chapter.raws.l[[1]])



# 6.3 Extracting Word Usage Means #
#**calculate the mean word frequency for all chapters
#** Mean word usage is one way of thinking about lexical variety (p. 65)
lapply(chapter.raws.l,mean)

#*organiza o simplifica el despliegue de lo anterior
mean.word.use.m <- do.call(rbind, lapply(chapter.raws.l,mean))

dim(mean.word.use.m)

#*grafico de lo calculado
plot(mean.word.use.m, type="h")

#**normalizacion de lo calculado para todos los capitulos; muestra las desviaciones respecto a la media para cada capitulo
scale(mean.word.use.m)

#**grafica de normalizacion
plot(scale(mean.word.use.m), type="h")

# 	6.4 Ranking the Values 	#
#** rank in decreasing rank order; it return a vector of numbers 
order(mean.word.use.m)
order(mean.word.use.m, decreasing=TRUE)

#** reorder vector of means 
mean.word.use.m[order(mean.word.use.m, decreasing=TRUE),]
